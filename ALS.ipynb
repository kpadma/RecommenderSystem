{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the anime names and description data \n",
    "ani = sqlContext.read.csv(\"/FileStore/tables/t15c1kha1493595884357/anime_clean.tsv\", sep=\"\\t\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ani.dtypes\n",
    "print ani.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the ratings file\n",
    "rate = sqlContext.read.csv(\"/FileStore/tables/6v019hww1493595654706/rating_cleaned.csv\", sep=\",\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print rate.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data for ALS \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "lines = sc.textFile(\"/FileStore/tables/2yo25zip1493507658625/rating.csv\")\n",
    "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "                                     rating=float(p[2])))\n",
    "ratings = sqlContext.read.csv(\"/FileStore/tables/2yo25zip1493507658625/rating.csv\", sep=\",\", header=True, inferSchema = True)\n",
    "\n",
    "ratings_filt = ratings.filter(ratings.rating!=-1)\n",
    "print ratings.count(), ratings_filt.count()\n",
    "print ratings.show(5)\n",
    "print ratings_filt.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the count Null Values\n",
    "print ratings.na.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ALS for different Combinations for Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data to test and train\n",
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=75, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate rmse \n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=90, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=60, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=40, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(nonnegative = True, rank = 20, maxIter=40, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(alpha = 1.0, nonnegative = True, rank = 20, maxIter=40, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(alpha = 10.0, nonnegative = True, rank = 15, maxIter=40, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model with a sample Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id =11024\n",
    "test_anime= 148\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the names for anime id\n",
    "names= sqlContext.read.csv(\"/FileStore/tables/t15c1kha1493595884357/anime_name.csv\", header=True, inferSchema=True)\n",
    "names.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions.filter(predictions.user_id==test_id).sort('prediction', ascending=False).join(names).show(5)\n",
    "#predictions.filter(predictions.user_id==test_id).sort('prediction', ascending=False).show(5)\n",
    "#predictions.na.drop().join(names, predictions.anime_id==names.anime_id, 'inner').filter(predictions.user_id!=42309).sort('prediction', ascending=False).select(\"name\", \"prediction\", \"user_id\").groupBy(\"name\").count().sort('count', ascending=False).show()\n",
    "import pyspark.sql.functions as f\n",
    "predictions.na.drop().join(names, predictions.anime_id==names.anime_id, 'inner').filter(predictions.user_id!=66941).select(\"name\", \"prediction\").groupBy(\"name\").agg(f.avg('prediction')).sort('avg(prediction)', ascending=False).show(25)\n",
    "#.sort('count', ascending=False).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.na.drop().join(names, predictions.anime_id==names.anime_id, 'inner').sort('prediction', ascending=False).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.na.drop().filter(predictions.user_id!=test_id).join(names, predictions.anime_id==names.anime_id, 'inner').sort('prediction', ascending=False).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_2 = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse_1 = evaluator.evaluate(prediction_2.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse_1))\n",
    "prediction_2.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "(training, test) = ratings_filt.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=60, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "predictions.na.drop().sort(\"prediction\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ALS Algorithm using Cross Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(als.regParam, [0.1, 0.2, 0.3])\n",
    "             .addGrid(als.maxIter, [10, 5, 2])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(training)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# addGrid(als.maxIter, [2, 3, 4])\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "predictions = cvModel.transform(test)\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "#evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .addGrid(als.maxIter, [10, 5, 2])\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "predictions = cvModel.transform(test)\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "#evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(als.regParam, [0.1, 0.2, 0.3])\n",
    "             .addGrid(als.maxIter, [10, 15, 20])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(training)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .addGrid(als.maxIter, [10, 5, 2])\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "predictions = cvModel.transform(test)\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "#evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "RS",
  "notebookId": 3764841841335367
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
