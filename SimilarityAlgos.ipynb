{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUTS \n",
    "ratings= sqlContext.read.csv('/FileStore/tables/qthksaj91493514788924/rating_cleaned.csv', sep=',' , inferSchema=True, header=True)\n",
    "anime = sqlContext.read.csv('/FileStore/tables/ezjvoa7k1493514682679/anime_clean.tsv', sep='\\t', inferSchema=True, header=True)\n",
    "names= sqlContext.read.csv('/FileStore/tables/p4kjul861493612915497/anime_name.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Required Data \n",
    "animes = spark.createDataFrame(anime.rdd.map(lambda x: (x[0], x[1].lower().replace('\"',\"\").replace(' ',\"\").split(','))), ['anime_id',                      'genre'])\n",
    "print animes.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find Count of unique Genre\n",
    "count  = []\n",
    "for i in animes.collect():\n",
    "  count.extend(i[1])\n",
    "print len(count), len(set(count))\n",
    "count_genre = len(set(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For Vectorize the data \n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count Vectorizer Fitting \n",
    "cv = CountVectorizer(inputCol=\"genre\", outputCol=\"features\", vocabSize=count_genre, minDF=2.0)\n",
    "cvmodel = cv.fit(animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform Data using Count Vectorizer\n",
    "animes_transformed = cvmodel.transform(animes)\n",
    "animes_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Sparse Vector to Dense\n",
    "fnldata = spark.createDataFrame(animes_transformed.select('anime_id', 'features').rdd.map(lambda x: (x[0], Vectors.dense(x[1]))), ['id', 'DenseVector'])\n",
    "fnldata.take(2)\n",
    "fnldata.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get distance functions from Sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the \n",
    "test_id = 28977\n",
    "test_vector= fnldata.rdd.lookup(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate Cosine Similarity between the test id and rdd elements\n",
    "cosine_dist =spark.createDataFrame(fnldata.rdd.map(lambda x: (x[0], float(cosine_similarity(x[1], test_vector)[0][0]))), ['anime_id', 'cosine_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take 26 of the values for recommendation\n",
    "cosine_recomm=cosine_dist.join(names, names.anime_id==cosine_dist.anime_id).sort('cosine_sim',ascending=False).take(26)\n",
    "pprint(cosine_recomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate Cosine Similarity between the test id and rdd elements\n",
    "euclidean_dist =spark.createDataFrame(fnldata.rdd.map(lambda x: (x[0], float( euclidean_distances(x[1], test_vector)[0][0]))), ['anime_id', 'euclidean_distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take 26 of the values for recommendation\n",
    "euclidean_recomm=euclidean_dist.join(names, names.anime_id==euclidean_dist.anime_id).sort('euclidean_distances',ascending=True).take(26)\n",
    "pprint(euclidean_recomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate Manhattan Dist between the test id and rdd elements\n",
    "manhattan_dist =spark.createDataFrame(fnldata.rdd.map(lambda x: (x[0], float( manhattan_distances(x[1], test_vector)[0][0]))), ['anime_id', 'manhattan_distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take 26 of the values for recommendation\n",
    "manhattan_recomm=manhattan_dist.join(names, names.anime_id==manhattan_dist.anime_id).sort('manhattan_distances',ascending=True).take(26)\n",
    "pprint(manhattan_recomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate Jaccard Similarity between the test id and rdd elements\n",
    "jaccard_sim =spark.createDataFrame(fnldata.rdd.map(lambda x: (x[0], float(jaccard_similarity_score( test_vector[0], x[1])))), ['anime_id', 'jaccard_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take 26 of the values for recommendation\n",
    "jaccard_recomm=jaccard_sim.join(names, names.anime_id==jaccard_sim.anime_id).sort('jaccard_similarity',ascending=False).take(26)\n",
    "pprint(jaccard_recomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print the recommedations\n",
    "print \"Cosine , Euclidean, Manhattan, Jaccard\"\n",
    "fnl_recomm=[]\n",
    "for i in range(len(cosine_recomm)) :\n",
    "  print (cosine_recomm[i][3],  euclidean_recomm[i][3], manhattan_recomm[i][3], jaccard_recomm[i][3])\n",
    "  fnl_recomm.append(cosine_recomm[i][3])\n",
    "  fnl_recomm.append(euclidean_recomm[i][3])\n",
    "  fnl_recomm.append(manhattan_recomm[i][3])\n",
    "  fnl_recomm.append(jaccard_recomm[i][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(fnl_recomm), len(set(fnl_recomm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint (set(fnl_recomm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "BD_Proj_Cosine",
  "notebookId": 2452567509011526
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
